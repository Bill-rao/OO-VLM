TRAIN:
  ENABLE: True
  DATASET: sth_fusion
  BATCH_SIZE: 256
  EVAL_PERIOD: 1
  CHECKPOINT_PERIOD: 5
  AUTO_RESUME: True
  GRADIENT_ACCUMULATE: 0
  IS_RESET_EPOCH: False
DATA:
  NUM_FRAMES: 16
  NUM_BBOX_FRAMES: 32  # COORD
  SAMPLING_RATE: 4
  RANDOM_FLIP: False
  TRAIN_JITTER_SCALES: [ 256, 320 ]
  TRAIN_CROP_SIZE: 224
  TEST_CROP_SIZE: 224
  INPUT_CHANNEL_NUM: [ 3 ]
  # PATH_TO_DATA_DIR: path-to-imagenet-dir
  TRAIN_JITTER_SCALES_RELATIVE: [ 0.08, 1.0 ]
  TRAIN_JITTER_ASPECT_RELATIVE: [ 0.75, 1.3333 ]
#UNIFORMERV2:
#  BACKBONE: 'uniformerv2_l14'
#  N_LAYERS: 16
#  N_DIM: 1024
#  N_HEAD: 16
#  MLP_FACTOR: 4.0
#  BACKBONE_DROP_PATH_RATE: 0.2
#  DROP_PATH_RATE: 0.4
#  MLP_DROPOUT: [ 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5 ]
#  CLS_DROPOUT: 0.5
#  RETURN_LIST: [ 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23 ]
#  DW_REDUCTION: 1.5
#  NO_LMHRA: False
#  DOUBLE_LMHRA: True
#  TEMPORAL_DOWNSAMPLE: True
FUSION:
  ENABLE: True
  RGB_ENABLE: True
  MAX_WORDS: 35
  RGB_BACKBONE: "videomaev2_giant"
  RGB_WIDTH: 1408
  LANGUAGE_CONFIG_PATH: "exp/data_record/videomaev2_giant/med_config.json"  # Bert
  LANGUAGE_PRETRAIN_PATH: "model/bert/pytorch_model.bin"  # Bert
  LANGUAGE_TOKENIZER_DIR_PATH: "model/bert"
  LANGUAGE_MODEL: "bert" # bert roberta
  COORD_PRETRAIN_PATH: "model/b64_f32_desktop_sthv2_6d56de14/best.pth.tar"
  OBJ_CLASS_NUM: 9 # 7+2'
  COORD_FEATURE_DIM: 256
  COORD_NUM_HEAD: 4
  COORD_NUM_SPATIAL_LAYER: 3
  COORD_NUM_TEMPORAL_LAYER: 3
  COORD_NUM_FRAME: 32
  EMBED_DIM: 1408
  QUEUE_SIZE: 57600
  #  QUEUE_SIZE: 50400
  MOMENTUM: 0.995
  ALPHA: 0.4
  K_TEST: 128
  NEGATIVE_ALL_RANK: False
  NUM_QUERY_TOKEN: 6
  NUM_COORD_RGB_TOKEN: 42
#AUG:
#  NUM_SAMPLE: 1
#  ENABLE: True
#  COLOR_JITTER: 0.4
#  AA_TYPE: rand-m7-n4-mstd0.5-inc1
#  INTERPOLATION: bicubic
#  RE_PROB: 0.
#  RE_MODE: pixel
#  RE_COUNT: 1
#  RE_SPLIT: False
BN:
  USE_PRECISE_STATS: False
  NUM_BATCHES_PRECISE: 200
SOLVER:
  ZERO_WD_1D_PARAM: True
  BASE_LR_SCALE_NUM_SHARDS: True
  BASE_LR: 5e-5
  COSINE_AFTER_WARMUP: True
  COSINE_END_LR: 2e-7
  WARMUP_START_LR: 1e-7
  WARMUP_EPOCHS: 0.
  LR_POLICY: cosine
  MAX_EPOCH: 50
  MOMENTUM: 0.9
  WEIGHT_DECAY: 0.000005
  OPTIMIZING_METHOD: adamw
MODEL:
  NUM_CLASSES: 174
  ARCH: fusion
  MODEL_NAME: Fusion
  LOSS_FUNC: cross_entropy
  DROPOUT_RATE: 0.1
  USE_CHECKPOINT: False
  CHECKPOINT_NUM: [ 0 ]
TEST:
  ENABLE: True
  DATASET: sth_fusion
  BATCH_SIZE: 256
  NUM_SPATIAL_CROPS: 3
  NUM_ENSEMBLE_VIEWS: 2
DATA_LOADER:
  NUM_WORKERS: 8
  PIN_MEMORY: True
TENSORBOARD:
  ENABLE: False
LOG_MODEL_INFO: False
NUM_GPUS: 8
NUM_SHARDS: 1
RNG_SEED: 0
OUTPUT_DIR: ./
